{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Sales Forecasting and Customer Segmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set style for visualizations\n",
        "plt.style.use('ggplot')\n",
        "sns.set_palette(\"Set2\")\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "plt.rcParams['font.size'] = 12\n",
        "\n",
        "# Load the datasets\n",
        "retail_df = pd.read_csv('retail_sales_data.csv')\n",
        "reviews_df = pd.read_csv('product_reviews.csv')\n",
        "\n",
        "# Convert date column to datetime\n",
        "retail_df['date'] = pd.to_datetime(retail_df['date'])\n",
        "\n",
        "# Add temporal features\n",
        "retail_df['year'] = retail_df['date'].dt.year\n",
        "retail_df['month'] = retail_df['date'].dt.month\n",
        "retail_df['day'] = retail_df['date'].dt.day\n",
        "retail_df['day_of_week'] = retail_df['date'].dt.dayofweek\n",
        "retail_df['is_weekend'] = retail_df['day_of_week'].isin([5, 6]).astype(int)\n",
        "retail_df['quarter'] = retail_df['date'].dt.quarter\n",
        "\n",
        "# Handle missing values\n",
        "print(\"Handling missing values...\")\n",
        "# Fill missing weather with mode\n",
        "retail_df['weather'] = retail_df['weather'].fillna(retail_df['weather'].mode()[0])\n",
        "# Fill missing promotion with 'None'\n",
        "retail_df['promotion'] = retail_df['promotion'].fillna('None')\n",
        "# Fill missing special_event with False\n",
        "retail_df['special_event'] = retail_df['special_event'].fillna(False)\n",
        "# Fill missing dominant_age_group with mode\n",
        "retail_df['dominant_age_group'] = retail_df['dominant_age_group'].fillna(retail_df['dominant_age_group'].mode()[0])\n",
        "# Fill missing numerical values with median\n",
        "for col in ['num_customers', 'total_sales', 'online_sales', 'in_store_sales', 'avg_transaction', 'return_rate']:\n",
        "    retail_df[col] = retail_df[col].fillna(retail_df[col].median())\n",
        "\n",
        "print(\"Missing values after imputation:\")\n",
        "print(retail_df.isnull().sum())\n",
        "\n",
        "# Feature Engineering\n",
        "print(\"\\nPerforming feature engineering...\")\n",
        "\n",
        "# Create lag features for time series\n",
        "def create_lag_features(df, group_cols, target_col, lag_periods):\n",
        "    df_copy = df.copy()\n",
        "    for lag in lag_periods:\n",
        "        df_copy[f'{target_col}_lag_{lag}'] = df_copy.groupby(group_cols)[target_col].shift(lag)\n",
        "    return df_copy\n",
        "\n",
        "# Create rolling window features\n",
        "def create_rolling_features(df, group_cols, target_col, windows, functions):\n",
        "    df_copy = df.copy()\n",
        "    for window in windows:\n",
        "        for func in functions:\n",
        "            df_copy[f'{target_col}_roll_{window}_{func.__name__}'] = df_copy.groupby(group_cols)[target_col].transform(\n",
        "                lambda x: x.shift(1).rolling(window=window, min_periods=1).agg(func))\n",
        "    return df_copy\n",
        "\n",
        "# Sort by date for proper time series analysis\n",
        "retail_df = retail_df.sort_values(['store_id', 'category', 'date'])\n",
        "\n",
        "# Create lag features for total_sales (1, 7, and 14 days)\n",
        "retail_df = create_lag_features(retail_df, ['store_id', 'category'], 'total_sales', [1, 7, 14])\n",
        "\n",
        "# Create rolling window features (7, 14, and 30 days with mean and std)\n",
        "retail_df = create_rolling_features(retail_df, ['store_id', 'category'], 'total_sales', [7, 14, 30], [np.mean, np.std])\n",
        "\n",
        "# Create interaction features\n",
        "retail_df['price_per_customer'] = retail_df['total_sales'] / retail_df['num_customers']\n",
        "retail_df['online_ratio'] = retail_df['online_sales'] / retail_df['total_sales']\n",
        "retail_df['weekend_promotion'] = retail_df['is_weekend'] * (retail_df['promotion'] != 'None').astype(int)\n",
        "\n",
        "# Drop rows with NaN values created by lag features\n",
        "retail_df = retail_df.dropna()\n",
        "\n",
        "print(\"Feature engineering completed. New shape:\", retail_df.shape)\n",
        "\n",
        "# Part 1: Sales Forecasting\n",
        "print(\"\\n=== Sales Forecasting Model ===\")\n",
        "\n",
        "# Prepare data for forecasting\n",
        "# We'll forecast total_sales for each store and category combination\n",
        "\n",
        "# Select features for forecasting\n",
        "forecast_features = [\n",
        "    'month', 'day', 'day_of_week', 'is_weekend', 'quarter',\n",
        "    'weather', 'promotion', 'special_event', 'dominant_age_group',\n",
        "    'num_customers', 'online_sales', 'in_store_sales', 'avg_transaction',\n",
        "    'total_sales_lag_1', 'total_sales_lag_7', 'total_sales_lag_14',\n",
        "    'total_sales_roll_7_mean', 'total_sales_roll_14_mean', 'total_sales_roll_30_mean',\n",
        "    'total_sales_roll_7_std', 'total_sales_roll_14_std', 'total_sales_roll_30_std',\n",
        "    'price_per_customer', 'online_ratio', 'weekend_promotion'\n",
        "]\n",
        "\n",
        "# Target variable\n",
        "target = 'total_sales'\n",
        "\n",
        "# Prepare categorical features\n",
        "cat_features = ['weather', 'promotion', 'special_event', 'dominant_age_group']\n",
        "num_features = [f for f in forecast_features if f not in cat_features]\n",
        "\n",
        "# Create a preprocessor\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), num_features),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_features)\n",
        "    ])\n",
        "\n",
        "# Create a time series split for validation\n",
        "tscv = TimeSeriesSplit(n_splits=3)\n",
        "\n",
        "# Function to evaluate forecasting model\n",
        "def evaluate_forecast_model(X, y, model, cv):\n",
        "    mae_scores = []\n",
        "    rmse_scores = []\n",
        "    r2_scores = []\n",
        "    \n",
        "    for train_idx, test_idx in cv.split(X):\n",
        "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "        \n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "        \n",
        "        mae_scores.append(mean_absolute_error(y_test, y_pred))\n",
        "        rmse_scores.append(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
        "        r2_scores.append(r2_score(y_test, y_pred))\n",
        "    \n",
        "    return {\n",
        "        'MAE': np.mean(mae_scores),\n",
        "        'RMSE': np.mean(rmse_scores),\n",
        "        'R2': np.mean(r2_scores)\n",
        "    }\n",
        "\n",
        "# Select a sample store and category for demonstration\n",
        "store_id = 'store_1'\n",
        "category = 'Electronics'\n",
        "sample_data = retail_df[(retail_df['store_id'] == store_id) & (retail_df['category'] == category)]\n",
        "\n",
        "X = sample_data[forecast_features]\n",
        "y = sample_data[target]\n",
        "\n",
        "# Create and evaluate XGBoost model\n",
        "xgb_model = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regressor', xgb.XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42))\n",
        "])\n",
        "\n",
        "print(f\"Training forecasting model for {store_id}, {category}...\")\n",
        "forecast_metrics = evaluate_forecast_model(X, y, xgb_model, tscv)\n",
        "print(\"Forecasting Model Metrics:\")\n",
        "for metric, value in forecast_metrics.items():\n",
        "    print(f\"{metric}: {value:.4f}\")\n",
        "\n",
        "# Feature importance\n",
        "xgb_model.fit(X, y)\n",
        "feature_importance = xgb_model.named_steps['regressor'].feature_importances_\n",
        "\n",
        "# Get feature names after one-hot encoding\n",
        "preprocessor.fit(X)\n",
        "feature_names = (\n",
        "    num_features +\n",
        "    list(preprocessor.named_transformers_['cat'].get_feature_names_out(cat_features))\n",
        ")\n",
        "\n",
        "# Create feature importance DataFrame\n",
        "importance_df = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Importance': feature_importance\n",
        "}).sort_values('Importance', ascending=False)\n",
        "\n",
        "# Plot feature importance\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.barplot(x='Importance', y='Feature', data=importance_df.head(15))\n",
        "plt.title(f'Top 15 Feature Importance for Sales Forecasting ({store_id}, {category})')\n",
        "plt.tight_layout()\n",
        "plt.savefig('forecast_feature_importance.png')\n",
        "plt.close()\n",
        "\n",
        "# Visualize actual vs predicted values\n",
        "X_train, X_test = X.iloc[:-30], X.iloc[-30:]\n",
        "y_train, y_test = y.iloc[:-30], y.iloc[-30:]\n",
        "\n",
        "xgb_model.fit(X_train, y_train)\n",
        "y_pred = xgb_model.predict(X_test)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(y_test.index, y_test.values, label='Actual', marker='o')\n",
        "plt.plot(y_test.index, y_pred, label='Predicted', marker='x')\n",
        "plt.title(f'Actual vs Predicted Sales ({store_id}, {category})')\n",
        "plt.xlabel('Date Index')\n",
        "plt.ylabel('Total Sales')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig('forecast_actual_vs_predicted.png')\n",
        "plt.close()\n",
        "\n",
        "# Part 2: Customer Segmentation\n",
        "print(\"\\n=== Customer Segmentation Analysis ===\")\n",
        "\n",
        "# Aggregate data at the store level for segmentation\n",
        "store_features = retail_df.groupby('store_id').agg({\n",
        "    'total_sales': 'mean',\n",
        "    'online_sales': 'mean',\n",
        "    'in_store_sales': 'mean',\n",
        "    'num_customers': 'mean',\n",
        "    'avg_transaction': 'mean',\n",
        "    'return_rate': 'mean',\n",
        "    'online_ratio': 'mean',\n",
        "    'price_per_customer': 'mean',\n",
        "    'is_weekend': 'mean'  # Proportion of weekend sales\n",
        "}).reset_index()\n",
        "\n",
        "# Calculate additional KPIs\n",
        "store_features['online_to_instore_ratio'] = store_features['online_sales'] / store_features['in_store_sales']\n",
        "\n",
        "# Prepare data for clustering\n",
        "X_cluster = store_features.drop('store_id', axis=1)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_cluster)\n",
        "\n",
        "# Determine optimal number of clusters using silhouette score\n",
        "silhouette_scores = []\n",
        "K = range(2, 6)\n",
        "for k in K:\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
        "    kmeans.fit(X_scaled)\n",
        "    silhouette_scores.append(silhouette_score(X_scaled, kmeans.labels_))\n",
        "\n",
        "# Plot silhouette scores\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(K, silhouette_scores, 'bo-')\n",
        "plt.xlabel('Number of clusters')\n",
        "plt.ylabel('Silhouette Score')\n",
        "plt.title('Silhouette Score Method For Optimal k')\n",
        "plt.grid(True)\n",
        "plt.savefig('optimal_clusters.png')\n",
        "plt.close()\n",
        "\n",
        "# Choose optimal number of clusters\n",
        "optimal_k = K[np.argmax(silhouette_scores)]\n",
        "print(f\"Optimal number of clusters: {optimal_k}\")\n",
        "\n",
        "# Apply K-means clustering with optimal k\n",
        "kmeans = KMeans(n_clusters=optimal_k, random_state=42)\n",
        "store_features['cluster'] = kmeans.fit_predict(X_scaled)\n",
        "\n",
        "# Analyze clusters\n",
        "cluster_analysis = store_features.groupby('cluster').agg({\n",
        "    'total_sales': 'mean',\n",
        "    'online_sales': 'mean',\n",
        "    'in_store_sales': 'mean',\n",
        "    'num_customers': 'mean',\n",
        "    'avg_transaction': 'mean',\n",
        "    'return_rate': 'mean',\n",
        "    'online_ratio': 'mean',\n",
        "    'price_per_customer': 'mean',\n",
        "    'online_to_instore_ratio': 'mean'\n",
        "}).reset_index()\n",
        "\n",
        "print(\"\\nCluster Analysis:\")\n",
        "print(cluster_analysis)\n",
        "\n",
        "# Visualize clusters\n",
        "plt.figure(figsize=(12, 8))\n",
        "for i in range(optimal_k):\n",
        "    cluster_data = store_features[store_features['cluster'] == i]\n",
        "    plt.scatter(\n",
        "        cluster_data['online_ratio'],\n",
        "        cluster_data['price_per_customer'],\n",
        "        label=f'Cluster {i}',\n",
        "        s=100\n",
        "    )\n",
        "    \n",
        "    # Add store labels\n",
        "    for _, row in cluster_data.iterrows():\n",
        "        plt.annotate(row['store_id'], (row['online_ratio'], row['price_per_customer']), \n",
        "                     fontsize=9, ha='center')\n",
        "\n",
        "plt.xlabel('Online Sales Ratio')\n",
        "plt.ylabel('Price Per Customer')\n",
        "plt.title('Store Clusters by Online Ratio and Price Per Customer')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.savefig('store_clusters.png')\n",
        "plt.close()\n",
        "\n",
        "# Radar chart for cluster profiles\n",
        "def radar_chart(cluster_data, cluster_col='cluster'):\n",
        "    # Select features for the radar chart\n",
        "    features = ['total_sales', 'online_ratio', 'num_customers', \n",
        "                'avg_transaction', 'return_rate', 'price_per_customer']\n",
        "    \n",
        "    # Number of variables\n",
        "    N = len(features)\n",
        "    \n",
        "    # Create a figure\n",
        "    fig = plt.figure(figsize=(12, 8))\n",
        "    \n",
        "    # Normalize the data for radar chart\n",
        "    scaler = StandardScaler()\n",
        "    cluster_data_scaled = pd.DataFrame(\n",
        "        scaler.fit_transform(cluster_data[features]),\n",
        "        columns=features\n",
        "    )\n",
        "    cluster_data_scaled[cluster_col] = cluster_data[cluster_col]\n",
        "    \n",
        "    # Compute the angle for each feature\n",
        "    angles = [n / float(N) * 2 * np.pi for n in range(N)]\n",
        "    angles += angles[:1]  # Close the loop\n",
        "    \n",
        "    # Initialize the plot\n",
        "    ax = plt.subplot(111, polar=True)\n",
        "    \n",
        "    # Draw one axis per variable and add labels\n",
        "    plt.xticks(angles[:-1], features, size=12)\n",
        "    \n",
        "    # Draw the y-axis labels (0 to 2)\n",
        "    ax.set_rlabel_position(0)\n",
        "    plt.yticks([0, 1, 2], [\"0\", \"1\", \"2\"], color=\"grey\", size=10)\n",
        "    plt.ylim(0, 2)\n",
        "    \n",
        "    # Plot each cluster\n",
        "    for i in range(optimal_k):\n",
        "        cluster_values = cluster_data_scaled[cluster_data_scaled[cluster_col] == i][features].mean().values.flatten().tolist()\n",
        "        cluster_values += cluster_values[:1]  # Close the loop\n",
        "        ax.plot(angles, cluster_values, linewidth=2, linestyle='solid', label=f'Cluster {i}')\n",
        "        ax.fill(angles, cluster_values, alpha=0.1)\n",
        "    \n",
        "    # Add legend\n",
        "    plt.legend(loc='upper right', bbox_to_anchor=(0.1, 0.1))\n",
        "    plt.title('Cluster Profiles', size=15)\n",
        "    \n",
        "    return fig\n",
        "\n",
        "# Create radar chart\n",
        "radar_fig = radar_chart(store_features)\n",
        "plt.savefig('cluster_profiles_radar.png')\n",
        "plt.close()\n",
        "\n",
        "# Create cluster profile descriptions\n",
        "cluster_profiles = []\n",
        "for i in range(optimal_k):\n",
        "    cluster_data = cluster_analysis[cluster_analysis['cluster'] == i]\n",
        "    \n",
        "    # Determine key characteristics\n",
        "    if cluster_data['online_ratio'].values[0] > cluster_analysis['online_ratio'].mean():\n",
        "        online_status = \"High online sales ratio\"\n",
        "    else:\n",
        "        online_status = \"Low online sales ratio\"\n",
        "        \n",
        "    if cluster_data['price_per_customer'].values[0] > cluster_analysis['price_per_customer'].mean():\n",
        "        price_status = \"High average spend per customer\"\n",
        "    else:\n",
        "        price_status = \"Low average spend per customer\"\n",
        "        \n",
        "    if cluster_data['return_rate'].values[0] > cluster_analysis['return_rate'].mean():\n",
        "        return_status = \"High return rate\"\n",
        "    else:\n",
        "        return_status = \"Low return rate\"\n",
        "    \n",
        "    # Create profile\n",
        "    profile = f\"Cluster {i}: {online_status}, {price_status}, {return_status}\"\n",
        "    cluster_profiles.append(profile)\n",
        "    \n",
        "    # List stores in this cluster\n",
        "    stores = store_features[store_features['cluster'] == i]['store_id'].tolist()\n",
        "    stores_str = \", \".join(stores)\n",
        "    cluster_profiles.append(f\"   Stores: {stores_str}\")\n",
        "\n",
        "print(\"\\nCluster Profiles:\")\n",
        "for profile in cluster_profiles:\n",
        "    print(profile)\n",
        "\n",
        "# Return key results\n",
        "print(\"\\nSales Forecasting and Customer Segmentation Analysis Completed\")\n",
        "print(f\"Forecasting model for {store_id}, {category} achieved R² of {forecast_metrics['R2']:.4f}\")\n",
        "print(f\"Stores were segmented into {optimal_k} distinct clusters\")\n",
        "print(\"Visualizations saved as PNG files\")\n",
        "\n",
        "# Return the dataframes for further analysis\n",
        "store_features.head(), forecast_metrics"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
